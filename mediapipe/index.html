

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../yolo/">
      
      
        <link rel="next" href="../face_recognition/">
      
      
      <link rel="icon" href="../img/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>MediaPipe - AI in robotics</title>
      
    
    

      <link rel="stylesheet" href="../assets/stylesheets/main.84d31ad4.min.css">
      
      


    
<link rel="stylesheet" type="text/css" href="../css/fonts.css" />
<link rel="stylesheet" type="text/css" href="../css/style.css" />

    
      
    
    
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    

<script type="text/javascript">
    if ( window !== window.parent ) {
        // The page is in an iframe
        window.addEventListener("DOMContentLoaded", function externalLinks() {
            var anchors = document.getElementsByTagName("a");
            for (var i = 0; i < anchors.length; i++) {
                    if (anchors[i].hostname !== window.location.hostname) {
                        anchors[i].setAttribute("target", "_blank");
                        anchors[i].setAttribute("rel", "noopener");
                    }
                    // Handle 'Open in SWAN' badges in the parent JupyterLab window
                    if (anchors[i].hostname == 'cern.ch' && anchors[i].pathname == '/swanserver/cgi-bin/go') {
                        const projectUrl = new URLSearchParams(anchors[i].search).get('projurl');
                        if (projectUrl) {
                                anchors[i].onclick = () => {
                                window.parent.postMessage(projectUrl,'*');
                                //  Skip redirecting the iframe page to the link 
                                return false;
                            }
                        }
                    }
            }
        }); 
    }
</script>

  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mediapipe" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI in robotics" class="md-header__button md-logo" aria-label="AI in robotics" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI in robotics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              MediaPipe
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI in robotics" class="md-nav__button md-logo" aria-label="AI in robotics" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    AI in robotics
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Введение
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../hardware/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Способы внедрения
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../pycharm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Работа в PyCharm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../yolo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    YOLO
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    MediaPipe
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    MediaPipe
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      Установка необходимого и первый запуск
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Установка необходимого и первый запуск">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-python-39-312" class="md-nav__link">
    <span class="md-ellipsis">
      1. Python 3.9-3.12
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. Установить нужные библиотеки
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. Запустить тестовый скрип
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      Примеры
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Примеры">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#facemesh" class="md-nav__link">
    <span class="md-ellipsis">
      Facemesh
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../face_recognition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Распознавание лица
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech-to-text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Распознавание речи
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../KWS/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Распознавание ключевых слов
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Большие языковые модели
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../tgai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Telegram Bot + AI
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../py%2Bard/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python + Arduino
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../jetson/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Jetson Nano
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../raspberry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Raspberry Pi
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../kinect/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    XBOX Kinect
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../cams/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ИИ камеры
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../assistants/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ИИ помощники
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../todo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    На будущее
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      Установка необходимого и первый запуск
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Установка необходимого и первый запуск">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-python-39-312" class="md-nav__link">
    <span class="md-ellipsis">
      1. Python 3.9-3.12
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. Установить нужные библиотеки
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. Запустить тестовый скрип
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      Примеры
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Примеры">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#facemesh" class="md-nav__link">
    <span class="md-ellipsis">
      Facemesh
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="mediapipe">Использование MediaPipe</h1>
<p>MediaPipe Solutions предоставляет набор библиотек и инструментов, позволяющих быстро применять методы искусственного интеллекта (ИИ) и машинного обучения (МО) в ваших приложениях. Вы можете сразу подключить эти решения к своим приложениям, настроить их в соответствии со своими потребностями и использовать на нескольких платформах разработки.
Официальный сайт <a href="https://ai.google.dev/edge/mediapipe/solutions/guide?hl=ru">MediaPipe</a>  </p>
<h3 id="_1">Установка необходимого и первый запуск</h3>
<h5 id="1-python-39-312">1. Python 3.9-3.12</h5>
<ul>
<li>Скачать можно на официальном сайте <a href="https://www.python.org/downloads/windows/">python.org</a>.  </li>
<li>Самые новые версии могут временно не поддерживаться YOLO.  </li>
<li>Прямая ссылка на <a href="https://www.python.org/ftp/python/3.12.10/python-3.12.10-amd64.exe">Python 3.12.10</a> (100% рабочая)</li>
<li>При установке нужно устанавливать от имени администратора и поставить галочку в Add to PATH</li>
</ul>
<h5 id="2">2. Установить нужные библиотеки</h5>
<ul>
<li>в командную строку написать: <blockquote>
<p>pip3 install mediapipe opencv-python</p>
</blockquote>
</li>
</ul>
<h5 id="3">3. Запустить тестовый скрип</h5>
<p>Запустить python IDLE -&gt; file -&gt; new file<br />
Написать код и сохранить в любую папку<br />
Код находит и отслеживает положение рук и пальцев. <a href="https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/hands.md">Полная статья</a></p>
<pre><code>import cv2
import mediapipe as mp
import time

mp_hands = mp.solutions.hands
mp_draw  = mp.solutions.drawing_utils
mp_style = mp.solutions.drawing_styles

cap = cv2.VideoCapture(0)

with mp_hands.Hands(
    model_complexity=1,             # 0/1/2: сложность модели. Выше — точнее, но медленнее (по умолчанию 1)
    max_num_hands=4,                # максимум обнаруживаемых рук в кадре
    min_detection_confidence=0.5,   # порог уверенности для первичного детекта рук (0..1)
    min_tracking_confidence=0.5     # порог для продолжения трекинга; ниже — вернётся к детекту (0..1)
) as hands:
    while cv2.waitKey(1) != 27:

        ok, frame = cap.read()
        if not ok: break

        frame = cv2.flip(frame, 1)
        start_time = time.perf_counter()

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        res = hands.process(rgb)

        if res.multi_hand_landmarks:
            for lm, hness in zip(res.multi_hand_landmarks, res.multi_handedness):
                mp_draw.draw_landmarks(
                    frame, lm, mp_hands.HAND_CONNECTIONS,
                    mp_style.get_default_hand_landmarks_style(),
                    mp_style.get_default_hand_connections_style()
                )

        end_time = time.perf_counter()
        fps = 1 / (end_time - start_time)
        cv2.putText(frame, f&quot;FPS: {int(fps)}&quot;, (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(frame, f&quot;Press 'Esc' to exit&quot;, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)

        cv2.imshow(&quot;Hands&quot;, frame)

cap.release()
cv2.destroyAllWindows()

</code></pre>
<p><img src="../img/img_22.png" alt="desc" width="500"> </p>
<h4 id="_2">Примеры</h4>
<h5 id="facemesh">Facemesh</h5>
<p>MediaPipe Face Mesh — это решение, которое оценивает 468 трёхмерных ориентиров лица в режиме реального времени, даже на мобильных устройствах. <a href="https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md">Полная статья</a>  </p>
<details>
<summary>Face mesh</summary>


<pre><code>
import cv2
import mediapipe as mp
import time

mp_face  = mp.solutions.face_mesh
mp_draw  = mp.solutions.drawing_utils
mp_style = mp.solutions.drawing_styles

cap = cv2.VideoCapture(0)

with mp_face.FaceMesh(
    static_image_mode=False,        # потоковое видео; True — для обработки отдельных фото
    max_num_faces=4,                # максимум обнаруживаемых лиц в кадре
    refine_landmarks=True,          # детализированные точки (радужка, губы)
    min_detection_confidence=0.5,   # порог уверенности первичного детекта (0..1)
    min_tracking_confidence=0.5     # порог продолжения трекинга (0..1)
) as face:
    while cv2.waitKey(1) != 27:

        ok, frame = cap.read()
        if not ok:
            break

        frame = cv2.flip(frame, 1)
        start_time = time.perf_counter()

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        res = face.process(rgb)

        if res.multi_face_landmarks:
            for lm in res.multi_face_landmarks:
                # Треугольная сетка лица
                mp_draw.draw_landmarks(
                    frame, lm, mp_face.FACEMESH_TESSELATION,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_style.get_default_face_mesh_tesselation_style()
                )
                # Контуры лица
                mp_draw.draw_landmarks(
                    frame, lm, mp_face.FACEMESH_CONTOURS,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_style.get_default_face_mesh_contours_style()
                )
                # Радужки глаз
                mp_draw.draw_landmarks(
                    frame, lm, mp_face.FACEMESH_IRISES,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_style.get_default_face_mesh_iris_connections_style()
                )

        end_time = time.perf_counter()
        fps = 1.0 / max(1e-6, (end_time - start_time))
        cv2.putText(frame, f&quot;FPS: {int(fps)}&quot;, (50, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(frame, &quot;Press 'Esc' to exit&quot;, (50, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)

        cv2.imshow(&quot;Face Mesh&quot;, frame)

cap.release()
cv2.destroyAllWindows()

</code></pre>


</details>
<p><br></p>
<p>Маска очков на лицо. В папку с кодом загрузить файл  </p>
<blockquote>
<p><a href="../img/glasses.png">glasses.png</a></p>
</blockquote>
<details>
<summary>Очки</summary>


<pre><code>
import cv2
import mediapipe as mp
import numpy as np
import time, math, os

mp_face  = mp.solutions.face_mesh
mp_draw  = mp.solutions.drawing_utils
mp_style = mp.solutions.drawing_styles

# ==== Параметры ====
PNG_PATH = &quot;glasses.png&quot;       # Опционально: PNG c альфа-каналом (очки), центр в середине файла
TINT_ALPHA = 0.35              # Прозрачность затемнения &quot;линз&quot; (0..1)
FRAME_THICK = 4                # Толщина контура &quot;оправы&quot; (px)
SCALE_W = 3                  # Ширина очков = IPD * SCALE_W
SCALE_H = 0.45                 # Относительная высота очков от ширины

cap = cv2.VideoCapture(0)

# Загрузка PNG, если есть
png_rgba = None
if os.path.isfile(PNG_PATH):
    png_rgba = cv2.imread(PNG_PATH, cv2.IMREAD_UNCHANGED)

def alpha_blend_rgba(bg_bgr, fg_rgba, cx, cy):
    &quot;&quot;&quot;Альфа-наложение RGBA поверх bg, центрируя в (cx,cy).&quot;&quot;&quot;
    fh, fw = fg_rgba.shape[:2]
    x1 = int(cx - fw // 2); y1 = int(cy - fh // 2)
    x2 = x1 + fw;          y2 = y1 + fh

    # Клип по границам
    bh, bw = bg_bgr.shape[:2]
    x1c, y1c = max(0, x1), max(0, y1)
    x2c, y2c = min(bw, x2), min(bh, y2)
    if x1c &gt;= x2c or y1c &gt;= y2c: 
        return

    roi_bg = bg_bgr[y1c:y2c, x1c:x2c]
    roi_fg = fg_rgba[(y1c - y1):(y2c - y1), (x1c - x1):(x2c - x1)]

    alpha = (roi_fg[..., 3:4].astype(np.float32)) / 255.0
    fg_bgr = roi_fg[..., :3].astype(np.float32)
    bg_bgr[y1c:y2c, x1c:x2c] = (alpha * fg_bgr + (1 - alpha) * roi_bg.astype(np.float32)).astype(np.uint8)

def rotate_scale_rgba(img_rgba, angle_deg, scale):
    &quot;&quot;&quot;Поворот и масштаб RGBA.&quot;&quot;&quot;
    h, w = img_rgba.shape[:2]
    M = cv2.getRotationMatrix2D((w/2, h/2), angle_deg, scale)
    out = cv2.warpAffine(img_rgba, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_TRANSPARENT)
    return out

def iris_center_px(lm_list, ids, W, H):
    xs = [lm_list[i].x * W for i in ids]
    ys = [lm_list[i].y * H for i in ids]
    return (float(np.mean(xs)), float(np.mean(ys)))

with mp_face.FaceMesh(
    static_image_mode=False,        
    max_num_faces=2,                
    refine_landmarks=True,          # даёт 5 точек радужки на каждый глаз (всего 478)
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
) as face:
    while cv2.waitKey(1) != 27:
        ok, frame = cap.read()
        if not ok: break

        frame = cv2.flip(frame, 1)
        start_time = time.perf_counter()

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        rgb.flags.writeable = False
        res = face.process(rgb)
        rgb.flags.writeable = True

        H, W = frame.shape[:2]

        if res.multi_face_landmarks:
            # Берём первое лицо
            lm = res.multi_face_landmarks[0].landmark

            # Индексы радужек (mediapipe, при refine_landmarks=True)
            right_iris = [469, 470, 471, 472, 468]  # правая (для пользователя — слева)
            left_iris  = [474, 475, 476, 477, 473]  # левая  (для пользователя — справа)

            # Центры радужек в пикселях
            rx, ry = iris_center_px(lm, right_iris, W, H)
            lx, ly = iris_center_px(lm, left_iris,  W, H)

            # Межзрачковое расстояние и угол наклона
            ipd = math.hypot(lx - rx, ly - ry)
            angle = -math.degrees(math.atan2(ly - ry, lx - rx))
            cx, cy = (rx + lx) * 0.5, (ry + ly) * 0.5

            # Масштаб по ширине
            target_w = max(1, int(ipd * SCALE_W))
            scale = target_w / png_rgba.shape[1]
            rotated = rotate_scale_rgba(png_rgba, angle, scale)
            alpha_blend_rgba(frame, rotated, int(cx), int(cy))

        end_time = time.perf_counter()
        fps = 1.0 / max(1e-6, (end_time - start_time))
        cv2.putText(frame, f&quot;FPS: {int(fps)}&quot;, (50, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(frame, &quot;Press 'Esc' to exit&quot;, (50, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)

        cv2.imshow(&quot;FaceMesh Virtual Try-On&quot;, frame)

cap.release()
cv2.destroyAllWindows()

</code></pre>


</details>
<p><br></p>
<p>Измерение расстояния для лица. <a href="https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/iris.md">Полная статья</a></p>
<details>
<summary>Расстояние</summary>


<pre><code>
import cv2
import mediapipe as mp
import time, math

# ==== Параметры ====
CALIB_DIST_M = 0.60           # метров: на каком расстоянии нажмёте 'C'
SMOOTH_ALPHA = 0.85           # 0..1, больше — плавнее (эксп. сглаживание)

mp_face  = mp.solutions.face_mesh
cap = cv2.VideoCapture(0)

calib_C = None                # константа масштаба = ipd_px_at_calib * CALIB_DIST_M
dist_smooth = None

# Индексы центра радужек (нужен refine_landmarks=True)
RIGHT_IRIS_CENTER = 468
LEFT_IRIS_CENTER  = 473

with mp_face.FaceMesh(
    static_image_mode=False,
    max_num_faces=1,
    refine_landmarks=True,      # включает точки радужки (всего 478)
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
) as face:

    while True:
        ok, frame = cap.read()
        if not ok: break

        frame = cv2.flip(frame, 1)
        start = time.perf_counter()

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        rgb.flags.writeable = False
        res = face.process(rgb)
        rgb.flags.writeable = True

        H, W = frame.shape[:2]
        ipd_px = None

        if res.multi_face_landmarks:
            lm = res.multi_face_landmarks[0].landmark

            # Берём центры радужек
            rx, ry = lm[RIGHT_IRIS_CENTER].x * W, lm[RIGHT_IRIS_CENTER].y * H
            lx, ly = lm[LEFT_IRIS_CENTER].x  * W, lm[LEFT_IRIS_CENTER].y  * H

            ipd_px = math.hypot(lx - rx, ly - ry)

            # Визуализация центров
            cv2.circle(frame, (int(rx), int(ry)), 3, (0,255,255), -1, cv2.LINE_AA)
            cv2.circle(frame, (int(lx), int(ly)), 3, (0,255,255), -1, cv2.LINE_AA)
            cv2.line(frame, (int(rx), int(ry)), (int(lx), int(ly)), (0,255,255), 2, cv2.LINE_AA)

        # Оценка дистанции
        if calib_C is not None and ipd_px and ipd_px &gt; 1:
            dist_m = calib_C / ipd_px                 # d ≈ (s0*d0)/s
            if dist_smooth is None:
                dist_smooth = dist_m
            else:
                dist_smooth = SMOOTH_ALPHA*dist_smooth + (1-SMOOTH_ALPHA)*dist_m
            text = f&quot;Distance: {dist_smooth:.2f} m&quot;
        else:
            text = &quot;Press 'C' at known distance&quot;

        # HUD
        end = time.perf_counter()
        fps = 1.0 / max(1e-6, (end - start))
        cv2.putText(frame, f&quot;FPS: {int(fps)}&quot;, (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)
        cv2.putText(frame, text, (20, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2, cv2.LINE_AA)
        if ipd_px:
            cv2.putText(frame, f&quot;IPD px: {ipd_px:.1f}&quot;, (20, 120),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,255), 2, cv2.LINE_AA)
        if calib_C is not None:
            cv2.putText(frame, f&quot;Calib C: {calib_C:.1f}&quot;, (20, 160),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,200,255), 2, cv2.LINE_AA)
        cv2.putText(frame, &quot;C=Calibrate  Esc=Exit&quot;, (20, H-20),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (200,200,200), 2, cv2.LINE_AA)

        cv2.imshow(&quot;Iris distance meter&quot;, frame)

        k = cv2.waitKey(1) &amp; 0xFF
        if k == 27:  # Esc
            break
        elif k in (ord('c'), ord('C')):
            # Калибровка: на расстоянии CALIB_DIST_M нажмите 'C'
            if ipd_px and ipd_px &gt; 1:
                calib_C = ipd_px * CALIB_DIST_M
                dist_smooth = None  # сброс фильтра

cap.release()
cv2.destroyAllWindows()

</code></pre>


</details>
<p><br></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class=" text">
    <p>SWAN © Copyright CERN 2016-2025. All rights reserved.</p>
    <ul>
        <li><a target="_blank" href="https://cern.ch/swan/">Home</a></li>
        <li><a target="_blank" href="https://cern.ch/swan-community/">Community</a></li>
        <li><a target="_blank" href="https://cern.service-now.com/service-portal/?id=functional_element&name=swan">Support</a></li>
        <li><a target="_blank" href="https://github.com/swan-cern">Github</a></li>
    </ul>
    <p class="poweredby">Powered by <strong><a href="https://www.mkdocs.org">MkDocs</a></strong> and <strong><a href="https://squidfunk.github.io/mkdocs-material/"> Material for MkDocs</a></strong></p>
</div>
<div class="md-layout-grid--align-right logo">
    <img src="../images/logo_cern.png" alt="CERN">
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../search/main.js"></script>
      
    
  </body>
</html>